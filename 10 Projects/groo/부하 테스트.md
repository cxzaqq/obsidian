# 1. dummy data 삽입

user: 30,000
forest: 30,000
user_item: 224,700
placement: 3,368,799
diary: 6,739,606
diary_emotion: 13,479,212

약 23,800,000개의 데이터 삽입

# 2. 모니터링 도구 적용

## prometheus

1. 설치
2. EC2 gradle에 의존성 추가 및 경로 security 필터 제외
```
implementation 'org.springframework.boot:spring-boot-starter-actuator'  
runtimeOnly 'io.micrometer:micrometer-registry-prometheus'
```

```
.requestMatchers("/actuator/prometheus").permitAll()
```
3. prometheus.yml EC2 endpoint로 설정
4. 실행 후 확인(`localhost:9090`)

## grafana

1. 설치
2. 관리자 권한으로 bash 실행 후 실행
3. 로그인(`localhost:3000`)
4. Data sources -> add data source -> prometheus -> `localhost:9090`입력 -> save & test
5. Dashboard -> new -> import -> id에 `20727` 입력 -> Load

# 3. Jmeter 사용

1. 설치
2. 실행
3. test plan 우클릭 -> add -> threads -> thread group
4. thread group 우클릭 -> add -> config element -> http request defaults
5. 시나리오 추가
6. prometheus, grafana 실행 후 테스트 시작

threads: 20
Ramp-up period 60s
Loop Count: Infinite
thread delay: 2000ms

# 4. 결과 분석

## 로컬

![[http response time.png]]

로컬에서 로직 수정 후 배포 환경에서 테스트 예정

### 수정할 로직

#### 1. 일기 상세 조회

`/api/diary/{forestId}/date`

```xml
<resultMap id="DiaryWithEmotionResultMap" type="com.x1.groo.forest.emotion.query.dto.QueryForestEmotionDiaryByDateDTO">  
    <id property="diaryId" column="diary_id"/>  
    <result property="content" column="content"/>  
    <result property="createdAt" column="created_at"/>  
    <collection property="emotions" ofType="string" column="diary_id" select="findEmotionsByDiaryId"/>  
</resultMap>

<select id="findDiaryByDateAndForestId" resultMap="DiaryWithEmotionResultMap">  
    SELECT DISTINCT  
           d.id AS diary_id  
         , d.content  
         , d.created_at  
      FROM diary d  
      JOIN user u ON d.user_id = u.id  
      JOIN forest f ON d.forest_id = f.id  
      LEFT JOIN shared_forest sf ON f.id = sf.forest_id  
     WHERE f.id = #{forestId}  
       AND d.created_at BETWEEN #{startDateTime} AND #{endDateTime}  
</select>

<select id="findEmotionsByDiaryId" resultType="string">  
    SELECT emotion  
      FROM diary_emotion  
     WHERE diary_id = #{diary_id}  
</select>
```

- 문제 및 개선 사항
1. DB를 두 번 다녀옴 => 1번으로 변경 필요 => join 적용
2. DISTINCT는 무거운 연산 => DISTINCT 제거

```xml
<resultMap id="DiaryWithEmotionResultMap" type="com.x1.groo.forest.emotion.query.dto.QueryForestEmotionDiaryByDateDTO">  
    <id property="diaryId" column="diary_id"/>  
    <result property="content" column="content"/>  
    <result property="createdAt" column="created_at"/>  
    <collection property="emotions" ofType="string" javaType="java.util.List">  
        <result column="emotion_name" />  
    </collection>
</resultMap>

<select id="findDiaryByDateAndForestId" resultMap="DiaryWithEmotionResultMap">  
    SELECT  
           d.id AS diary_id  
         , d.content  
         , d.created_at  
         , de.emotion AS emotion_name  
      FROM diary d  
      JOIN user u ON d.user_id = u.id  
      JOIN forest f ON d.forest_id = f.id  
      LEFT JOIN shared_forest sf ON f.id = sf.forest_id  
      LEFT JOIN diary_emotion de ON d.id = de.diary_id  
     WHERE f.id = #{forestId}  
       AND d.created_at BETWEEN #{startDateTime} AND #{endDateTime}
     ORDER BY d.id DESC  
</select>
```

DISTINCT 사용 시 DB가 중복된 행을 SQL 레벨에서 제거하느라 부하가 생김

DISTINCT를 제거해도 동작하는 이유는 mybatis의 `<id>` 태그가 그루핑의 기준이 됨.
mybatis가 중복된 레코드를 받으면 ResultMap이 작동하는데 `<id>` 태그에 지정된 `diary_id` 값이 변경될 때마다 새로운 상위 객체를 생성.
즉 `diary_id`가 동일하면 객체를 새로 생성하지 않음.
`<collection>` 태그는 상위 객체가 유지되는 동안(`diary_id`가 같을 때) 들어오는 각 레코드의 `emotion_name` 값을 모두 수집하여 리스트(`emotions`)에 추가.

=> 결과적으로 중복된 레코드가 넘어오지만 Java 객체에서는 알아서 제거가 됨

변경 전
![[diary date before.png]]
변경 후
![[diary date after.png]]

#### 2. 로그인

`/api/auth/login`



## AWS 배포 환경

### EC2

| 타입                 | 세부 정보        |
| ------------------ | ------------ |
| 인스턴스 타입            | t2.micro     |
| OS                 | Amazon Linux |
| CPU Credit Balance | 144          |

### RDS

| 타입   | 세부 정보           |
| ---- | --------------- |
| 엔진   | mariadb(11.4.5) |
| 클래스  | db.t3.micro     |
| 스토리지 | GP3(20GiB)      |

- 주의
	CPU Credit Balance가 0이 되면 EC2의 성능 저하가 시작됨. 인스턴스 타입의 한계 때문인지 코드의 문제 때문인지 판별 필요.

	DB 부하가 높게 나오는데 CPU 사용률은 낮다면 t3.micro의 CPU 한계에 도달한 것임

	즉 인위적인 제한이 성능의 병목일 가능성을 두고 잘 확인할 것

