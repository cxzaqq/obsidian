# 하위 문제 중첩(12.4)

## 피보나치 수열

```java
public static n fib(n) {

	if (n == 0 || n == 1) return n;

	return fib(n - 2) + fib(n - 1);
}
```

위 함수를 보면 자기 자신을 두 번씩 호출한다. 빅 오 관점에서 보면 이는 O(2<sup>n</sup>)이다.
`fib(5)`는 `fib(3)`, `fib(4)`를 호출하는데 `fib(4)`는 또 `fib(2)`, `fib(3)`을 호출한다.
이렇게 계속 진행하면 이미 호출한 함수를 또 불필요하게 호출하는 상황이 발생한다.

이런 하위 문제 중첩을 해결하는 방법으로 바로 동적 프로그래밍이 사용된다.("동적"이라는 단어에 너무 의미를 두지 말자.)

동적 프로그래밍에는 일반적으로 두 가지 기법 중 하나를 사용한다.

### 1. 메모제이션

먼저 계산한 함수 결과를 기억해 재귀 호출을 감소.

```java
import java.util.HashMap;
import java.util.Map;

public class FibonacciMem{

	private static Map<Integer, Long> memo = new HashMap<>();

	public static long fib(int n) {
		if (n <= 1) return n;

		// 이미 계산된 값이면 그대로 반환
		if (memo.containsKey(n)) {
			return memo.get(n);
		}

		// 새로 계산 후 메모에 저장
		long result = fib(n - 1) + fib(n - 2);
		memo.put(n, result);
	}

	return result;
}
```

원소 개수 n에 대해 함수를 호출하는 횟수는 2n-1번이다.
즉 O(n)이다. 위 재귀에서의 O(2<sup>n</sup>)보다 훨씬 효율적인 것을 알 수 있다.

### 2. 상향식

같은 문제를 재귀 대신 다른 방식으로 해결하는 것.

```java
public class FibonacciBottomUp {

	public static long fib(int n) {
		if (n <= 1) return n;

		long[] dp = new long[n + 1];
		dp[0] = 0;
		dp[1] = 1;

		for (int i = 2; i <= n; i++) {
			dp[i] = dp[i - 1] + dp[i - 2];
		}

		return dp[n];
	}

	public static long fibOptimized(int n) {
		if (n <= 1) return n;

		long prev = 0;
		long curr = 1;

		for (int i = 2; i <= n; i++) {
			long next = prev + curr;
			prev = curr;
			curr = next;
		}

		return curr;
	}
}
```

### 메모제이션 vs 상향식

어떤 기법이 더 나은가?

보통은 문제에 따라 그리고 애초에 왜 재귀를 사용하는지에 따라 다르지만 재귀가 매우 직관적이지 않은 이상 일반적으로 메모리를 적게 사용하는 상향식을 택하는 편이 더 낫다.
